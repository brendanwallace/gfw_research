{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# week 5\n",
    "## goals:\n",
    "- use the API code or the downloaded borders\n",
    "- input the actual boundaries of the MPAs\n",
    "- for now: ignore when MPAs were implemented, and:\n",
    "    - group by WDPAID\n",
    "    - produce list of WDPAIDs by how much effort was contained 2012-2016 (the existing data set)\n",
    "\n",
    "TODO:\n",
    "- convert points to a geopandas dataframe including the geoseries column (these are points? boxes?)\n",
    "\n",
    "\n",
    "## notes/learnings:\n",
    "- just download 3GiB protected areas from protected planet!\n",
    "- use geopandas to make a GeoDataFrame, the polygons are then a GeoSeries and we can ask .contains() or crosses() with the points (or boxes) of fishing effort\n",
    "- only 5699 unique WDPAIDs\n",
    "- need to construct southern latitude, western longitude, 100th degree box\n",
    "\n",
    "\n",
    "### largest MPAs:\n",
    "1. Marae Moana (Cook Islands) WDPAID = 555624907\n",
    "2. Ross Sea Region (Ross Sea)\n",
    "3. Papahanaumokuakea Marine National Monument (PMNM) [177, -160], [19, 32] 220201\n",
    "4. Natural Park of the Coral Sea\n",
    "5. Pacific Remote Islands (expanded) 400011\n",
    "6. Coral Sea Marine Park\n",
    "7. French Southern Territories Marine Reserve\n",
    "8. Phoenix Islands wdpaid: 309888\n",
    "9. Stellar Sea Lion Protection Areas (just Aleutian Islands 2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pywdpa\n",
    "import geopandas\n",
    "import contextily as ctx\n",
    "from shapely import geometry\n",
    "import pretty_html_table\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "pandas.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ab4992c26774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reads the downloaded WPDA polygon files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m protected_areas = pandas.concat([\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/WDPA_WDOECM_wdpa_shp/WDPA_WDOECM_wdpa_shp0/WDPA_WDOECM_wdpa_shp-polygons.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/WDPA_WDOECM_wdpa_shp/WDPA_WDOECM_wdpa_shp1/WDPA_WDOECM_wdpa_shp-polygons.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/WDPA_WDOECM_wdpa_shp/WDPA_WDOECM_wdpa_shp2/WDPA_WDOECM_wdpa_shp-polygons.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/3.0.5/libexec/lib/python3.9/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m                 )\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             return GeoDataFrame.from_features(\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mf_filt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/3.0.5/libexec/lib/python3.9/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36mfrom_features\u001b[0;34m(cls, features, crs, columns)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures_lst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0;31m# load geometry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__geo_interface__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# reads the downloaded WPDA polygon files\n",
    "protected_areas = pandas.concat([\n",
    "    geopandas.read_file(\"data/WDPA_WDOECM_wdpa_shp/WDPA_WDOECM_wdpa_shp0/WDPA_WDOECM_wdpa_shp-polygons.shp\"),\n",
    "    geopandas.read_file(\"data/WDPA_WDOECM_wdpa_shp/WDPA_WDOECM_wdpa_shp1/WDPA_WDOECM_wdpa_shp-polygons.shp\"),\n",
    "    geopandas.read_file(\"data/WDPA_WDOECM_wdpa_shp/WDPA_WDOECM_wdpa_shp2/WDPA_WDOECM_wdpa_shp-polygons.shp\")\n",
    "])\n",
    "# filters for marine only (may want to change this to 1 or 2 (2 is marine only, 1 is mixed, 0 is terrestrial))\n",
    "mpas = protected_areas[protected_areas[\"MARINE\"] == \"2\"]\n",
    "# delete the larger table - it's like 3 GiB and not needed past this point\n",
    "del(protected_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Marae Moana:\n",
    "mpas[mpas[\"WDPAID\"] == 555624907.0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMNM\n",
    "mpas[mpas[\"WDPAID\"] == 220201.0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique WDPAIDs are there in the whole set of MPAs?\n",
    "mpas[\"WDPAID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpas.sort_values(\"REP_M_AREA\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the fishing hours data (this is kinda slow)\n",
    "filenames = os.listdir('data/daily_csvs')\n",
    "\n",
    "# this might be faster but the status printout is nice:\n",
    "# points = pandas.concat([geopandas.read_file('data/daily_csvs/' + filename) for filename in filenames])\n",
    "\n",
    "counted = 0\n",
    "points = []\n",
    "for filename in filenames:\n",
    "    print(f'\\r {filename} {counted}/{len(filenames)}', end='')\n",
    "    points.append(pandas.read_csv('data/daily_csvs/' + filename,\n",
    "                                      dtype={'lat_bin': 'int16',\n",
    "                                             'lon_bin': 'int16',\n",
    "                                             'mmsi': 'int32',\n",
    "                                             'fishing_hours': 'float32'},\n",
    "                                 parse_dates=['date']))\n",
    "    counted += 1\n",
    "points = pandas.concat(points) # deliberately overwriting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_box(row, width=0.1):\n",
    "    x = float(row['lon_bin'] * width)\n",
    "    y = float(row['lat_bin'] * width)\n",
    "    return geometry.box(x, y, x+width, y+width)\n",
    "\n",
    "## Aggregate the points and bin them\n",
    "points_aggregate = points.groupby(['lat_bin', 'lon_bin']).aggregate({'lat_bin': 'first', 'lon_bin': 'first', 'fishing_hours': 'sum'})\n",
    "points_aggregate['geometry'] = points_aggregate.apply(compute_box, axis=1)\n",
    "geopoints = geopandas.GeoDataFrame(points_aggregate, geometry=points_aggregate['geometry']).set_crs(epsg=4326)\n",
    "\n",
    "\n",
    "points[['lat_bin_1d', 'lon_bin_1d']] = points[['lat_bin', 'lon_bin']].applymap(lambda x : int(round(x / 10)))\n",
    "points_aggregate_1d = points.groupby(['lat_bin_1d', 'lon_bin_1d']).aggregate({'lat_bin_1d': 'first', 'lon_bin_1d': 'first', 'fishing_hours': 'sum'})\n",
    "points_aggregate_1d.rename({'lat_bin_1d': 'lat_bin', 'lon_bin_1d': 'lon_bin'})\n",
    "\n",
    "\n",
    "\n",
    "points_aggregate_1d['geometry'] = points_aggregate.apply(\n",
    "    lambda x : compute_box(x, width=1), axis=1)\n",
    "\n",
    "geopoints_1d = geopandas.GeoDataFrame(points_aggregate_1d, geometry=points_aggregate_1d['geometry']).set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Plot it all!\n",
    "ax = geopoints.plot(column='fishing_hours', figsize=(20, 30), markersize=1, cmap='Blues', scheme='quantiles', legend=True)\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "ax = world.plot(\n",
    "    color='white', edgecolor='black', ax=ax, )\n",
    "\n",
    "\n",
    "\n",
    "marae = mpas[mpas[\"WDPAID\"] == 555624907.0]\n",
    "pmnm = mpas[mpas[\"WDPAID\"] == 220201.0]\n",
    "\n",
    "LINEWIDTH = 0.5\n",
    "mpas.plot(ax=ax, color='white', edgecolor='red', linewidth=LINEWIDTH)\n",
    "\n",
    "plt.title('fishing hours 2012-2016 in 0.1 degree aggregate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot it all!\n",
    "ax = geopoints_1d.plot(column='fishing_hours', figsize=(20, 30), markersize=1, cmap='Blues', scheme='quantiles', legend=True)\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "ax = world.plot(\n",
    "    color='white', edgecolor='black', ax=ax, )\n",
    "\n",
    "\n",
    "\n",
    "marae = mpas[mpas[\"WDPAID\"] == 555624907.0]\n",
    "pmnm = mpas[mpas[\"WDPAID\"] == 220201.0]\n",
    "\n",
    "LINEWIDTH = 0.5\n",
    "#marae.plot(ax=ax, color='white', edgecolor='red', linewidth=LINEWIDTH)\n",
    "#pmnm.plot(ax=ax, color='white', edgecolor='red')\n",
    "mpas.plot(ax=ax, color='white', edgecolor='red', linewidth=LINEWIDTH)\n",
    "\n",
    "plt.title('fishing hours 2012-2016 in 1 degree aggregate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce ranked list of mpas by amount of effort inside their borders\n",
    "# q - should we join by id or something first?\n",
    "\n",
    "mpas_ = mpas[['WDPAID', 'NAME', 'geometry', 'STATUS_YR', 'REP_M_AREA', 'REP_AREA', 'NO_TAKE']]\n",
    "joined_points = geopandas.sjoin(geopoints, mpas_, op='within')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_join(strings):\n",
    "    base = strings.iloc[0] if strings.any() else ''\n",
    "    for s in strings[1:]:\n",
    "        base = base if s in base else base + '|' + s\n",
    "    return base\n",
    "\n",
    "\n",
    "joined_points_aggregate = joined_points.groupby(['WDPAID'], as_index=False).aggregate({\n",
    "    'NAME': string_join,\n",
    "    'fishing_hours': 'sum',\n",
    "    'STATUS_YR': 'first',\n",
    "    'REP_M_AREA': 'sum',\n",
    "    'REP_AREA': 'sum',\n",
    "    'NO_TAKE': string_join,\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mpas = joined_points_aggregate.sort_values(\"fishing_hours\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "since_2016 = sorted_mpas[sorted_mpas['STATUS_YR'] >= 2016]\n",
    "since_2014 = sorted_mpas[sorted_mpas['STATUS_YR'] >= 2014]\n",
    "\n",
    "\n",
    "reprint = False\n",
    "if reprint:\n",
    "    f = open(\"2016_or_later.html\", \"w\")\n",
    "    f.write(pretty_html_table.build_table(since_2016, 'blue_light'))\n",
    "    f.close()\n",
    "\n",
    "    f = open(\"2014_or_later.html\", \"w\")\n",
    "    f.write(pretty_html_table.build_table(since_2014, 'blue_light'))\n",
    "    f.close()\n",
    "\n",
    "    f = open(\"all_mpas_by_fishing_hours.html\", \"w\")\n",
    "    f.write(pretty_html_table.build_table(sorted_mpas, 'blue_light'))\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
