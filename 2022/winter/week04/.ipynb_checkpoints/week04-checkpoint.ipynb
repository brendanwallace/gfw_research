{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# winter 2022 week03\n",
    "\n",
    "## goals:\n",
    "\n",
    "reload the data\n",
    "run util/load_data.py convert_all() function -- which loads everything and converts it to parquet\n",
    "\n",
    "## todo\n",
    "- \n",
    "\n",
    "\n",
    "## notes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brendan/Documents/mpa_project/gfw_research\n"
     ]
    }
   ],
   "source": [
    "cd /Users/brendan/Documents/mpa_project/gfw_research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pywdpa\n",
    "import geopandas\n",
    "import contextily as ctx\n",
    "from shapely import geometry\n",
    "from shapely import ops\n",
    "import pretty_html_table\n",
    "\n",
    "import util\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "pandas.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/brendan/Documents/mpa_project/gfw_research/data/\"\n",
    "FILENAME = \"mpatlas_20201223_clean/mpatlas_20201223_clean.shp\"\n",
    "\n",
    "import util\n",
    "\n",
    "#mpas = geopandas.read_file(DATA_PATH + FILENAME)\n",
    "# util.load_mpatlas_mpas()\n",
    "mpas = geopandas.read_parquet(\"data/mpas/mpatlas.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_year(year):\n",
    "    year = str(year)\n",
    "    print(f'\\r reading year {year}', end='')\n",
    "    return pandas.read_parquet(\"data/points/\" + year + \".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reading year 2020"
     ]
    }
   ],
   "source": [
    "points_by_year = {\n",
    "    year : load_year(year)\n",
    "    for year in range(2012, 2021)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 2020... done.\n",
      "converting to geo...  done.\n"
     ]
    }
   ],
   "source": [
    "# sample the points here before converting to geo\n",
    "# use the sampled points to find the mmsi that are interesting\n",
    "# only then should we get all of the points of relevent mmsi\n",
    "\n",
    "SAMPLE_RATIO = 50\n",
    "points_sampled = []\n",
    "for year, points in points_by_year.items():\n",
    "    print(f'\\rsampling {str(year)}... ', end='')\n",
    "    points_sampled.append(points.sample(frac=1/SAMPLE_RATIO))\n",
    "print('done.')\n",
    "points_sampled = pandas.concat(points_sampled)\n",
    "print(\"converting to geo...  \", end='')\n",
    "geopoints_sampled = util.convert_to_geo(points_sampled, box=True)\n",
    "print(\"done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/3.2.8/libexec/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3191: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "## Trying to recreate some week 6 tables and plots\n",
    "#\n",
    "geopoints = geopoints_sampled\n",
    "joined_points = geopandas.sjoin(geopoints, mpas, predicate='within')\n",
    "\n",
    "## Plot\n",
    "ax = joined_points.plot(column='fishing_hours', figsize=(20, 30), markersize=1, cmap='Blues', scheme='quantiles', legend=True)\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "ax = world.plot(\n",
    "    color='white', edgecolor='black', ax=ax, )\n",
    "\n",
    "LINEWIDTH = 0.5\n",
    "mpas.plot(ax=ax, color='None', edgecolor='red', linewidth=LINEWIDTH, alpha=0.5)\n",
    "\n",
    "plt.title('fishing hours inside mpas 2012-2016 in 0.1 degree aggregate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Actual good ones:\n",
    "- Natural Park of the Coral Seas, 2014 555577562, further off the east coast of Australia\n",
    "- Marae Moana/Cook Islands, 2017 555624907 - maybe the best one - middle of the Pacific\n",
    "- French Austral Lands and Seas, 2019 555697868 - south-east of Africa\n",
    "- Arquipélago Submarino Do Meteor, 2016 555514087 - Atlantic ocean Y shaped area\n",
    "- Coral Sea, 2018 555556875 just off the east coast of Australia\n",
    "- Pacífico Mexicano Profundo, 2018 555624307 southwest Mexican coast\n",
    "- Palau National Marine Sanctuary, 2015, 555622118 oceania (near indonesia, phillippines)\n",
    "\"\"\"\n",
    "\n",
    "# TODO - enter the dates, figure out how to consolidate the multiple-entry ones\n",
    "mpas_of_interest = [\n",
    "    (\"Marae Moana\", 555624907.0, \"2017-07-13\"),\n",
    "    (\"French Austral Lands and Seas\", 555697868, \"2019-01-01\"), # date is kind of a guess\n",
    "    (\"Arquipélago Submarino Do Meteor\", 555697868, \"2016-01-01\"), # date is rough\n",
    "    (\"Coral Sea\", 555556875, \"2018-07-01\"), # wikipedia\n",
    "    (\"Pacífico Mexicano Profundo\", 555624307, \"2016-07-12\"), \n",
    "    (\"PIPA\", 555512002, \"2015-01-01\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "pipa = mpas[mpas['wdpa_id'] == 555512002.0]\n",
    "\n",
    "pipa_res = util.analyze_mpa(geopoints_sampled, points_by_year, pipa, '2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "pitcairn = mpas[mpas['wdpa_id'] == 555624172.0]\n",
    "pitcairn_results = util.analyze_mpa(geopoints_sampled, points_by_year, pitcairn, \"2017-06-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
