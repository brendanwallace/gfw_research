{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# winter 2022 week03\n",
    "\n",
    "## goals:\n",
    "\n",
    "reload the data\n",
    "run util/load_data.py convert_all() function -- which loads everything and converts it to parquet\n",
    "\n",
    "## todo\n",
    "- ~add PIPA to list of interesting ones (57 -> 58)~\n",
    "- ~figure out how to get the thing to run faster (try to just use geopoints_sampled in analyze)~\n",
    "- ~final count of reduced fishing~\n",
    "- run the analyze thing over those 7/8\n",
    "- make those charts of in/out fishing effort of individual ships for those 7/8\n",
    "- make pictures of before/after fishing effort of individual ships for those 7/8 (could use consistent colors)\n",
    "\n",
    "THEN:\n",
    "- ~make ~table~ scatter-plot of (low, low), (low, high), (high, low), (high, high). etc. of the 171~\n",
    "- ~make table of (?, low), (?, high) of all the other ones~\n",
    "- try to categorize the mpas (sum up area and #, etc.)\n",
    "\n",
    "### of the 171:\n",
    "- about 14 showed notable decrease in both # hours and %\n",
    "- significant number (>100) of the 171 had no effort in before or after\n",
    "- very small number (3) showed a modest increase in % internal effort\n",
    "(should I quantify this by marine area?)\n",
    "- any sort of before/after pictures helpful? (at least make the before/after effort plots)\n",
    "- decide on criteria: % decrease by at least something\n",
    "- for all the matching ones, do a before/after\n",
    "\n",
    "\n",
    "\n",
    "AND THEN:\n",
    "- compare to the paper about 5 MPAs\n",
    "- email Dan to show him everything\n",
    "- title: what can GFW data tell us about the true protection of MPA?\n",
    "- two effective scenarios: (high, low) and (low, low) ~= (?, low)\n",
    "\n",
    "\n",
    "## notes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/brendan/Documents/projects/mpa_project/gfw_research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pywdpa\n",
    "import geopandas\n",
    "import contextily as ctx\n",
    "from shapely import geometry\n",
    "from shapely import ops\n",
    "import pretty_html_table\n",
    "import cProfile\n",
    "\n",
    "import util\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "pandas.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/brendan/Documents/projects/mpa_project/gfw_research/data/\"\n",
    "FILENAME = \"mpatlas_20201223_clean/mpatlas_20201223_clean.shp\"\n",
    "\n",
    "#mpas = geopandas.read_file(DATA_PATH + FILENAME)\n",
    "# util.load_mpatlas_mpas()\n",
    "mpas = geopandas.read_parquet(\"data/mpas/mpatlas.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_year(year):\n",
    "    year = str(year)\n",
    "    print(f'\\r reading year {year}', end='')\n",
    "    return pandas.read_parquet(\"data/points/\" + year + \".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_by_year = {\n",
    "    year : load_year(year)\n",
    "    for year in range(2012, 2021)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the points here before converting to geo\n",
    "# use the sampled points to find the mmsi that are interesting\n",
    "# only then should we get all of the points of relevent mmsi\n",
    "\n",
    "SAMPLE_RATIO = 100\n",
    "points_sampled = []\n",
    "for year, points in points_by_year.items():\n",
    "    print(f'\\rsampling {str(year)}... ', end='')\n",
    "    points_sampled.append(points.sample(frac=1/SAMPLE_RATIO))\n",
    "print('done.')\n",
    "points_sampled = pandas.concat(points_sampled)\n",
    "print(\"converting to geo...  \", end='')\n",
    "geopoints_sampled = util.convert_to_geo(points_sampled, box=True)\n",
    "print(\"done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_take = mpas[(mpas['no_take']=='All') & (mpas['implemente'])]\n",
    "of_interest_frame = no_take[\n",
    "    ((no_take['status_yea'] > 2012) | (no_take['implementa'] > '2012-01-01')) & no_take['implemente']]\n",
    "of_interest = [\n",
    "    (None, 555512002, 'Phoenix Island Protected Area', '2015-01-01')\n",
    "]\n",
    "# for i, row in no_take[no_take['status_yea'] > 2012].iterrows():\n",
    "for i, row in of_interest_frame.iterrows():\n",
    "    date = row['implementa']\n",
    "    if date is None:\n",
    "        date = str(row['status_yea'])\n",
    "    of_interest.append(\n",
    "        (row['mpa_id'], row['wdpa_id'], row['name'], date)\n",
    "    )\n",
    "\n",
    "np.random.shuffle(of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "folder_prefix = f'plots/{np.datetime64(\"now\")}'\n",
    "\n",
    "tables = pandas.DataFrame()\n",
    "summed_tables = pandas.DataFrame()\n",
    "j = 0\n",
    "for mpa_id, wdpa_id, name, date in of_interest:\n",
    "    j += 1\n",
    "    print(f'\\r{j}/{len(of_interest)} {mpa_id} {wdpa_id} {name} {date}                           ', end='')\n",
    "    mpa = None\n",
    "    if wdpa_id:\n",
    "        mpa = mpas[mpas['wdpa_id'] == wdpa_id].dissolve(by='wdpa_id')\n",
    "    elif mpa_id:\n",
    "        mpa = mpas[mpas['mpa_id'] == mpa_id].dissolve(by='mpa_id')\n",
    "    else:\n",
    "        print(f'no id for {name}, skipping')\n",
    "        continue\n",
    "        \n",
    "    folder = folder_prefix + f'/mpas/{name}/'\n",
    "    \n",
    "    returned = util.analyze_mpa(\n",
    "        geopoints_sampled, points_by_year, mpa, date, name, verbose=False,\n",
    "        plot=True, folder=folder)\n",
    "    if returned is not None:\n",
    "        table, points_of_mpa_ships = returned\n",
    "        table.insert(0, 'name', name)\n",
    "        table.insert(1, 'date', date)\n",
    "        table.insert(2, 'wdpa_id', wdpa_id)\n",
    "        table.insert(3, 'mpa_id', mpa_id)\n",
    "        \n",
    "        \n",
    "        html_table_blue_light = pretty_html_table.build_table(table, 'blue_light')\n",
    "    # Save to html file\n",
    "        with open(folder+'/individual_ships.html', 'w') as f:\n",
    "            f.write(html_table_blue_light)\n",
    "        \n",
    "        tables = tables.append(table)\n",
    "        \n",
    "        summed = table.groupby('name').aggregate({\n",
    "            'name': 'first',\n",
    "            'wdpa_id': 'first',\n",
    "            'mpa_id': 'first',\n",
    "            'date': 'first',\n",
    "            'mmsi': 'count',\n",
    "            'in_pre': 'sum',\n",
    "            'out_pre': 'sum',\n",
    "            'in_post': 'sum',\n",
    "            'out_post': 'sum'})\n",
    "        summed_tables = summed_tables.append(summed)\n",
    "    else:\n",
    "        summed_tables = summed_tables.append(\n",
    "            {'name': mpa.iloc[0]['name'], 'wdpa_id': wdpa_id, 'mpa_id': mpa_id, 'date': date}\n",
    "            , ignore_index=True)\n",
    "\n",
    "# Populate the summed tables percentages columns\n",
    "summed_tables['in_pre_p'] = summed_tables['in_pre'] / (summed_tables['in_pre'] + summed_tables['out_pre'])\n",
    "summed_tables['in_post_p'] = summed_tables['in_post'] / (summed_tables['in_post'] + summed_tables['out_post'])\n",
    "summed_tables['decrease'] = (summed_tables['in_pre_p'] - summed_tables['in_post_p'])/(summed_tables['in_pre_p'])\n",
    "summed_tables = summed_tables.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# Save to html files\n",
    "html_table = pretty_html_table.build_table(summed_tables.sort_values('decrease', ascending=False), 'blue_light')\n",
    "with open(folder_prefix+'/summed_effort_by_decrease.html', 'w') as f:\n",
    "    f.write(html_table)\n",
    "    \n",
    "\n",
    "html_table = pretty_html_table.build_table(summed_tables.sort_values('mmsi', ascending=False), 'blue_light')\n",
    "with open(folder_prefix+'/summed_effort_by_mmsi.html', 'w') as f:\n",
    "    f.write(html_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
