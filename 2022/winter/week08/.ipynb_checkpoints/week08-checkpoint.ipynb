{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# winter 2022 week03\n",
    "\n",
    "## goals:\n",
    "\n",
    "reload the data\n",
    "run util/load_data.py convert_all() function -- which loads everything and converts it to parquet\n",
    "\n",
    "## todo\n",
    "- ~add PIPA to list of interesting ones (57 -> 58)~\n",
    "- ~figure out how to get the thing to run faster (try to just use geopoints_sampled in analyze)~\n",
    "- ~final count of reduced fishing~\n",
    "- run the analyze thing over those 7/8\n",
    "- make those charts of in/out fishing effort of individual ships for those 7/8\n",
    "- make pictures of before/after fishing effort of individual ships for those 7/8 (could use consistent colors)\n",
    "\n",
    "THEN:\n",
    "- ~make ~table~ scatter-plot of (low, low), (low, high), (high, low), (high, high). etc. of the 171~\n",
    "- ~make table of (?, low), (?, high) of all the other ones~\n",
    "- try to categorize the mpas (sum up area and #, etc.)\n",
    "\n",
    "### of the 171:\n",
    "- about 14 showed notable decrease in both # hours and %\n",
    "- significant number (>100) of the 171 had no effort in before or after\n",
    "- very small number (3) showed a modest increase in % internal effort\n",
    "(should I quantify this by marine area?)\n",
    "- any sort of before/after pictures helpful? (at least make the before/after effort plots)\n",
    "- decide on criteria: % decrease by at least something\n",
    "- for all the matching ones, do a before/after\n",
    "\n",
    "\n",
    "\n",
    "AND THEN:\n",
    "- compare to the paper about 5 MPAs\n",
    "- email Dan to show him everything\n",
    "- title: what can GFW data tell us about the true protection of MPA?\n",
    "- two effective scenarios: (high, low) and (low, low) ~= (?, low)\n",
    "\n",
    "\n",
    "## notes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brendan/Documents/projects/mpa_project/gfw_research\n"
     ]
    }
   ],
   "source": [
    "cd /Users/brendan/Documents/projects/mpa_project/gfw_research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pywdpa\n",
    "import geopandas\n",
    "import contextily as ctx\n",
    "from shapely import geometry\n",
    "from shapely import ops\n",
    "import pretty_html_table\n",
    "import cProfile\n",
    "\n",
    "import util\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "pandas.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/brendan/Documents/projects/mpa_project/gfw_research/data/\"\n",
    "FILENAME = \"mpatlas_20201223_clean/mpatlas_20201223_clean.shp\"\n",
    "\n",
    "#mpas = geopandas.read_file(DATA_PATH + FILENAME)\n",
    "# util.load_mpatlas_mpas()\n",
    "mpas = geopandas.read_parquet(\"data/mpas/mpatlas.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_year(year):\n",
    "    year = str(year)\n",
    "    print(f'\\r reading year {year}', end='')\n",
    "    return pandas.read_parquet(\"data/points/\" + year + \".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reading year 2020"
     ]
    }
   ],
   "source": [
    "points_by_year = {\n",
    "    year : load_year(year)\n",
    "    for year in range(2012, 2021)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 2020... done.\n",
      "converting to geo...  done.\n"
     ]
    }
   ],
   "source": [
    "# sample the points here before converting to geo\n",
    "# use the sampled points to find the mmsi that are interesting\n",
    "# only then should we get all of the points of relevent mmsi\n",
    "\n",
    "SAMPLE_RATIO = 100\n",
    "points_sampled = []\n",
    "for year, points in points_by_year.items():\n",
    "    print(f'\\rsampling {str(year)}... ', end='')\n",
    "    points_sampled.append(points.sample(frac=1/SAMPLE_RATIO))\n",
    "print('done.')\n",
    "points_sampled = pandas.concat(points_sampled)\n",
    "print(\"converting to geo...  \", end='')\n",
    "geopoints_sampled = util.convert_to_geo(points_sampled, box=True)\n",
    "print(\"done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1056\n",
       "0      30\n",
       "Name: implemente, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpas[mpas['no_take'] == 'All']['implemente'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_take = mpas[(mpas['no_take']=='All') & (mpas['implemente'])]\n",
    "of_interest_frame = no_take[\n",
    "    ((no_take['status_yea'] > 2012) | (no_take['implementa'] > '2012-01-01')) & no_take['implemente']]\n",
    "of_interest = [\n",
    "    (None, 555512002, 'Phoenix Island Protected Area', '2015-01-01')\n",
    "]\n",
    "# for i, row in no_take[no_take['status_yea'] > 2012].iterrows():\n",
    "for i, row in of_interest_frame.iterrows():\n",
    "    date = row['implementa']\n",
    "    if date is None:\n",
    "        date = str(row['status_yea'])\n",
    "    of_interest.append(\n",
    "        (row['mpa_id'], row['wdpa_id'], row['name'], date)\n",
    "    )\n",
    "\n",
    "np.random.shuffle(of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/127 68808954 555556896 Oceanic Shoals - National Park Zone 2018-07-01                           running sjoin... \n",
      "found 11 sampled points in the mpa from 3 ships\n",
      "found 6297 points of mpa ships\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "import os\n",
    "\n",
    "tables = pandas.DataFrame()\n",
    "summed_tables = pandas.DataFrame()\n",
    "j = 0\n",
    "for mpa_id, wdpa_id, name, date in of_interest[8:9]:\n",
    "    j += 1\n",
    "    print(f'\\r{j}/{len(of_interest)} {mpa_id} {wdpa_id} {name} {date}                           ', end='')\n",
    "    mpa = None\n",
    "    if wdpa_id:\n",
    "        mpa = mpas[mpas['wdpa_id'] == wdpa_id].dissolve(by='wdpa_id')\n",
    "    elif mpa_id:\n",
    "        mpa = mpas[mpas['mpa_id'] == mpa_id].dissolve(by='mpa_id')\n",
    "    else:\n",
    "        print(f'no id for {name}, skipping')\n",
    "        continue\n",
    "        \n",
    "    folder = f'plots/mpas/{name}/'\n",
    "    \n",
    "#     returned = util.analyze_mpa(\n",
    "#         geopoints_sampled, points_by_year, mpa, date, name, verbose=False,\n",
    "#         plot_pre_post=True, folder=folder)\n",
    "    returned = util.analyze_mpa(\n",
    "        geopoints_sampled, points_by_year, mpa, date, name, verbose=True,\n",
    "        plot_pre_post=False, folder=None)\n",
    "    if returned is not None:\n",
    "        table, points_of_mpa_ships = returned\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1706884466.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [164]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for mmsi in mmsis:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "mmsis = points_of_mpa_ships['mmsi'].unique()\n",
    "start = np.datetime64('2012-01-01')\n",
    "end = np.datetime64('2021-01-01')\n",
    "days_in_interval = (end - start).item().days\n",
    "\n",
    "\n",
    "window=30\n",
    "\n",
    "\n",
    "def plot():\n",
    "    pass\n",
    "\n",
    "for mmsi in mmsis:\n",
    "    points = points_of_mpa_ships[points_of_mpa_ships['mmsi'] == mmsi]\n",
    "    effort_in = np.zeros(days_in_interval)\n",
    "    effort_out = np.zeros(days_in_interval)\n",
    "    for i, row in points.iterrows():\n",
    "        d = (row['date'] - start).days\n",
    "        if row['in_mpa']:\n",
    "            effort_in[d] += row['fishing_hours']\n",
    "        else:\n",
    "            effort_out[d] += row['fishing_hours']\n",
    "    plt.plot(X, avg(effort_in, window), label='in')\n",
    "    plt.plot(X, avg(effort_out, window), label='out')\n",
    "    plt.axvline(np.datetime64(date), c='black', ls=':')\n",
    "    plt.ylabel(f'fishing hours – {window}-day average')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'{mmsi} – {name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/127 15013 555556901 South-west Corner - National Park Zone 2018-07-01                                   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/geopandas/plotting.py:661: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "33/127 9395 555587195 Palaster Reef Sanctuary 2014-08-01                           \r",
      "34/127 15003 555556891 Mermaid Reef - National Park Zone 2018-07-01                           \r",
      "35/127 14978 555556866 Abrolhos - National Park Zone 2018-07-01                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendan/Documents/projects/mpa_project/gfw_research/util/analyze.py:156: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure()\n",
      "/Users/brendan/Documents/projects/mpa_project/gfw_research/util/analyze.py:156: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure()\n",
      "/Users/brendan/Documents/projects/mpa_project/gfw_research/util/analyze.py:156: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure()\n",
      "/Users/brendan/Documents/projects/mpa_project/gfw_research/util/analyze.py:89: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/127 None 555512002 Phoenix Island Protected Area 2015-01-01                                          3-19                           "
     ]
    }
   ],
   "source": [
    "import util\n",
    "folder_prefix = f'plots/{np.datetime64(\"now\")}'\n",
    "\n",
    "tables = pandas.DataFrame()\n",
    "summed_tables = pandas.DataFrame()\n",
    "j = 0\n",
    "for mpa_id, wdpa_id, name, date in of_interest:\n",
    "    j += 1\n",
    "    print(f'\\r{j}/{len(of_interest)} {mpa_id} {wdpa_id} {name} {date}                           ', end='')\n",
    "    mpa = None\n",
    "    if wdpa_id:\n",
    "        mpa = mpas[mpas['wdpa_id'] == wdpa_id].dissolve(by='wdpa_id')\n",
    "    elif mpa_id:\n",
    "        mpa = mpas[mpas['mpa_id'] == mpa_id].dissolve(by='mpa_id')\n",
    "    else:\n",
    "        print(f'no id for {name}, skipping')\n",
    "        continue\n",
    "        \n",
    "    folder = folder_prefix + f'/mpas/{name}/'\n",
    "    \n",
    "    returned = util.analyze_mpa(\n",
    "        geopoints_sampled, points_by_year, mpa, date, name, verbose=False,\n",
    "        plot=True, folder=folder)\n",
    "    if returned is not None:\n",
    "        table, points_of_mpa_ships = returned\n",
    "        table.insert(0, 'name', name)\n",
    "        table.insert(1, 'date', date)\n",
    "        table.insert(2, 'wdpa_id', wdpa_id)\n",
    "        table.insert(3, 'mpa_id', mpa_id)\n",
    "        \n",
    "        \n",
    "        html_table_blue_light = pretty_html_table.build_table(table, 'blue_light')\n",
    "    # Save to html file\n",
    "        with open(folder+'/individual_ships.html', 'w') as f:\n",
    "            f.write(html_table_blue_light)\n",
    "        \n",
    "        tables = tables.append(table)\n",
    "        \n",
    "        summed = table.groupby('name').aggregate({\n",
    "            'name': 'first',\n",
    "            'wdpa_id': 'first',\n",
    "            'mpa_id': 'first',\n",
    "            'date': 'first',\n",
    "            'mmsi': 'count',\n",
    "            'in_pre': 'sum',\n",
    "            'out_pre': 'sum',\n",
    "            'in_post': 'sum',\n",
    "            'out_post': 'sum'})\n",
    "        summed_tables = summed_tables.append(summed)\n",
    "    else:\n",
    "        summed_tables = summed_tables.append(\n",
    "            {'name': mpa.iloc[0]['name'], 'wdpa_id': wdpa_id, 'mpa_id': mpa_id, 'date': date}\n",
    "            , ignore_index=True)\n",
    "\n",
    "# Populate the summed tables percentages columns\n",
    "summed_tables['in_pre_p'] = summed_tables['in_pre'] / (summed_tables['in_pre'] + summed_tables['out_pre'])\n",
    "summed_tables['in_post_p'] = summed_tables['in_post'] / (summed_tables['in_post'] + summed_tables['out_post'])\n",
    "summed_tables['decrease'] = (summed_tables['in_pre_p'] - summed_tables['in_post_p'])/(summed_tables['in_pre_p'])\n",
    "summed_tables = summed_tables.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# Save to html files\n",
    "html_table = pretty_html_table.build_table(summed_tables.sort_values('decrease', ascending=False), 'blue_light')\n",
    "with open(folder_prefix+'/summed_effort_by_decrease.html', 'w') as f:\n",
    "    f.write(html_table)\n",
    "    \n",
    "\n",
    "html_table = pretty_html_table.build_table(summed_tables.sort_values('mmsi', ascending=False), 'blue_light')\n",
    "with open(folder_prefix+'/summed_effort_by_mmsi.html', 'w') as f:\n",
    "    f.write(html_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
