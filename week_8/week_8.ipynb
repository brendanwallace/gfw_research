{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# week 8\n",
    "\n",
    "## goals:\n",
    "- \n",
    "\n",
    "## todo\n",
    "- \n",
    "\n",
    "\n",
    "## notes:\n",
    "\n",
    "- specifically try to answer:\n",
    "    - \"you might want to just focus on MPAs that are beyond the continental shelves but we can talk about that.\"\n",
    "        - focus on high seas\n",
    "    - Should I include things like Ross Sea (which probably have a terrestrial component as well)?\n",
    "    - How do I use the post-2016 data? I'm in the google [permission?] group – can I make queries against an API?\n",
    "        - offline meeting with Dan to pull this data\n",
    "\n",
    "- GFW Data Training <- this is the google group to get added to\n",
    "\n",
    "\n",
    "- explicit theories about how they should behave and testing that\n",
    "\n",
    "- Ross Sea\n",
    "- PIPA\n",
    "- PMNM\n",
    "- south/central pacific ocean\n",
    "- pick out the 5 from Tim White's paper:\n",
    "    - PIPA - 2010\n",
    "    - Pacific Remote Islands - 2009\n",
    "    - PMNM - yes but low fishing effort (3258 hours, 2016)\n",
    "    - Pitcairn Islands - yes but low (101 hours, 2016)\n",
    "    - Nazca-Desventuradas - yes but low (68 hours, 2016)\n",
    "    \n",
    "Actual good ones:\n",
    "- Natural Park of the Coral Seas, 2014 555577562, further off the east coast of Australia\n",
    "- Marae Moana/Cook Islands, 2017 555624907 - maybe the best one - middle of the Pacific\n",
    "- French Austral Lands and Seas, 2019 555697868 - south-east of Africa\n",
    "- Arquipélago Submarino Do Meteor, 2016 555514087 - Atlantic ocean Y shaped area\n",
    "- Coral Sea, 2018 555556875 just off the east coast of Australia\n",
    "- Pacífico Mexicano Profundo, 2018 555624307 southwest Mexican coast\n",
    "- Palau National Marine Sanctuary, 2015, 555622118 oceania (near indonesia, phillippines) \n",
    "\n",
    "\n",
    "Can't use:\n",
    "- Phoenix Island - it's 2010\n",
    "\n",
    "\n",
    "A bunch of these at the top are coastal around Spain/France:\n",
    "- Espacio marino del Delta de l'Ebre-Illes Columbretes 2014\n",
    "- Espacio marino de la Costa da Morte 2014\n",
    "- Pertuis charentais - Rochebonne 2019\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brendan/Masters/gfw_research\n"
     ]
    }
   ],
   "source": [
    "cd /Users/brendan/Masters/gfw_research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pywdpa\n",
    "import geopandas\n",
    "import contextily as ctx\n",
    "from shapely import geometry\n",
    "import pretty_html_table\n",
    "\n",
    "import util \n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "pandas.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REUSABLE FUNCTIONS\n",
    "\n",
    "def join_on_lat_lon(points):\n",
    "    return points.groupby(['lat_bin', 'lon_bin'], as_index=False).aggregate({'lat_bin': 'first', 'lon_bin': 'first', 'fishing_hours': 'sum'})\n",
    "\n",
    "\n",
    "## Compute geometries for the points\n",
    "def compute_box(row, width=0.1):\n",
    "    x = float(row['lon_bin'] * width)\n",
    "    y = float(row['lat_bin'] * width)\n",
    "    return geometry.box(x, y, x+width, y+width)\n",
    "\n",
    "\n",
    "def convert_to_geo(points, box=True):\n",
    "    if box:\n",
    "        points['geometry'] = points.apply(compute_box, axis=1)\n",
    "        return geopandas.GeoDataFrame(points, geometry=points['geometry']).set_crs(epsg=4326)\n",
    "    # use points (not as precise, but cheaper)\n",
    "    else:\n",
    "        return geopandas.GeoDataFrame(\n",
    "            points,\n",
    "            geometry=geopandas.points_from_xy(points['lon_bin']*0.1 + 0.05, points['lat_bin']*0.1 + 0.05)\n",
    "        ).set_crs(epsg=4326)\n",
    "\n",
    "    \n",
    "def load_mpas():\n",
    "    # reads the downloaded WPDA polygon files\n",
    "    filenames = [\n",
    "        \"../data/WDPA_WDOECM_wdpa_shp/WDPA_WDOECM_wdpa_shp0/WDPA_WDOECM_wdpa_shp-polygons.shp\",\n",
    "        \"../data/WDPA_WDOECM_wdpa_shp/WDPA_WDOECM_wdpa_shp1/WDPA_WDOECM_wdpa_shp-polygons.shp\",\n",
    "        \"../data/WDPA_WDOECM_wdpa_shp/WDPA_WDOECM_wdpa_shp2/WDPA_WDOECM_wdpa_shp-polygons.shp\",\n",
    "    ]\n",
    "    protected_areas = []\n",
    "    counted = 0\n",
    "    for filename in filenames:\n",
    "        print(f'\\rloading mpas: {counted}/{len(filenames)}', end='')\n",
    "        protected_areas.append(geopandas.read_file(filename))\n",
    "        counted += 1\n",
    "    print(f'\\rloading mpas: {counted}/{len(filenames)} done.', end='')\n",
    "\n",
    "\n",
    "    protected_areas = pandas.concat(protected_areas)\n",
    "    # filters for marine only (may want to change this to 1 or 2 (2 is marine only, 1 is mixed, 0 is terrestrial))\n",
    "    mpas = protected_areas[protected_areas[\"MARINE\"] == \"2\"]\n",
    "    return mpas\n",
    "\n",
    "\n",
    "def load_points():\n",
    "    ## Load the fishing hours data (this is kinda slow)\n",
    "    print('loading points')\n",
    "    filenames = os.listdir('../data/daily_csvs')\n",
    "\n",
    "    # this might be faster but the status printout is nice:\n",
    "    # points = pandas.concat([geopandas.read_file('data/daily_csvs/' + filename) for filename in filenames])\n",
    "\n",
    "    counted = 0\n",
    "    points = []\n",
    "    for filename in filenames:\n",
    "        print(f'\\r {filename} {counted}/{len(filenames)}', end='')\n",
    "        points.append(pandas.read_csv('../data/daily_csvs/' + filename,\n",
    "                                          dtype={'lat_bin': 'int16',\n",
    "                                                 'lon_bin': 'int16',\n",
    "                                                 'mmsi': 'int32',\n",
    "                                                 'fishing_hours': 'float32'},\n",
    "                                     parse_dates=['date']))\n",
    "        counted += 1\n",
    "    print('\\nloaded.')\n",
    "    return pandas.concat(points) # deliberately overwriting points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mpas: 3/3 done.\n",
      "loading points\n",
      " 2013-12-20.csv 1826/1827\n",
      "loaded.\n"
     ]
    }
   ],
   "source": [
    "# sample the points here (100 of them) before converting to geo\n",
    "# use the sampled points to find the mmsi that are interesting\n",
    "# only then should I get all of the points of relevent mmsi\n",
    "\n",
    "mpas = util.load_mpas()\n",
    "full_points = util.load_points()\n",
    "SAMPLE_RATIO = 100\n",
    "points_sampled = full_points.sample(frac=1/SAMPLE_RATIO)\n",
    "geopoints_sampled = util.convert_to_geo(points_sampled, box=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_of_in_out_pre_post(points_of_mpa_ships, mpa, date):\n",
    "    \"\"\"\n",
    "    Returns a table with total fishing hours in/out of the mpa\n",
    "    \n",
    "    All it does is compute for each point whether it's in/out and before/after, and\n",
    "    then aggregates the totals per combination for each mmsi (each unique ship).\n",
    "    \n",
    "    Tries to take advantage of table groupby and aggregation to do this.\n",
    "    \"\"\"\n",
    "    geopoints_ = convert_to_geo(points_of_mpa_ships, box=True)\n",
    "    geopoints_['pre'] = geopoints_['date'] < date\n",
    "    # fastest way to do this is just this whole join:\n",
    "    print('running sjoin on geopoints of mpa ships')\n",
    "    geopoints_['in_mpa'] = ~geopandas.sjoin(geopoints_, mpa[['geometry']], how='left', op='within')['index_right'].isnull()\n",
    "    # TODO - what about on the border/indeterminate?\n",
    "    # geopoints_['intersects_mpa'] = ~geopandas.sjoin(geopoints_, mpa[['geometry']], how='left', op='intersects')['index_right'].isnull()\n",
    "    aggregated_ = geopoints_.groupby(['mmsi', 'in_mpa', 'pre'], as_index=False).aggregate({'fishing_hours': 'sum', 'mmsi': 'first'})\n",
    "    aggregated_['in_pre'] = aggregated_.apply(lambda row: row['fishing_hours'] if (row['in_mpa'] and row['pre']) else 0.0, axis=1)\n",
    "    aggregated_['out_pre'] = aggregated_.apply(lambda row: row['fishing_hours'] if (not row['in_mpa'] and row['pre']) else 0.0, axis=1)\n",
    "    aggregated_['in_post'] = aggregated_.apply(lambda row: row['fishing_hours'] if (row['in_mpa'] and not row['pre']) else 0.0, axis=1)\n",
    "    aggregated_['out_post'] = aggregated_.apply(lambda row: row['fishing_hours'] if (not row['in_mpa'] and not row['pre']) else 0.0, axis=1)\n",
    "    table = aggregated_.groupby(['mmsi'], as_index=False).aggregate({'in_pre': 'sum', 'out_pre': 'sum', 'in_post': 'sum', 'out_post': 'sum'})\n",
    "    table['pre_percent_in'] = table['in_pre'] / (table['in_pre'] + table['out_pre'])\n",
    "    table['post_percent_in'] = table['in_post'] / (table['in_post'] + table['out_post'])\n",
    "    return table\n",
    "\n",
    "   \n",
    "\n",
    "def plot_effort_with_world(effort, mpa, linewidth=0.5, title=''):\n",
    "    world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "    ax = world.plot(color='white', edgecolor='black', figsize=(20, 30))\n",
    "    effort.plot(column='fishing_hours', cmap='Blues', scheme='quantiles', ax=ax, legend=True)\n",
    "    mpa.plot(ax=ax, color='None', edgecolor='red', linewidth=linewidth, alpha=0.5)\n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "def analyze_mpa(geopoints_sampled, full_points, mpa, date, plot_pre_post=True):\n",
    "    #mpa = mpas[mpas['WDPAID'] == 555577562.0]\n",
    "\n",
    "    print('running sjoin... ', end='')\n",
    "    mpa_points = geopandas.sjoin(geopoints_sampled, mpa, op='within')\n",
    "    print('\\nfound {} sampled points in the mpa from {} ships'.format(\n",
    "        mpa_points.shape[0], mpa_points['mmsi'].nunique()))\n",
    "\n",
    "    points_of_mpa_ships = geopandas.GeoDataFrame(full_points[full_points['mmsi'].isin(mpa_points['mmsi'])])\n",
    "\n",
    "    print('found {} points of mpa ships'.format(points_of_mpa_ships.shape[0]))\n",
    "    \n",
    "    table = table_of_in_out_pre_post(points_of_mpa_ships, mpa, date,).sort_values('in_pre', ascending=False)\n",
    "    \n",
    "    pre = convert_to_geo(\n",
    "        join_on_lat_lon(points_of_mpa_ships[points_of_mpa_ships['date'] < date]), box=True)\n",
    "    post = convert_to_geo(\n",
    "        join_on_lat_lon(points_of_mpa_ships[points_of_mpa_ships['date'] >= date]), box=True)\n",
    "    \n",
    "    if plot_pre_post:\n",
    "        plot_effort_with_world(pre, mpa, title='effort pre-closure')\n",
    "        plot_effort_with_world(post, mpa, title='effort post-closure')\n",
    " \n",
    "    return table, pre, post\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sjoin... "
     ]
    }
   ],
   "source": [
    "coral_park = mpas[mpas['WDPAID'] == 555577562.0]\n",
    "coral_park_date = '2014-05-28'\n",
    "coral_park_results = util.analyze_mpa(geopoints_sampled, full_points, coral_park, coral_park_date)\n",
    "coral_park_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 1/100 sampling\n",
    "pipa = mpas[mpas['WDPAID'] == 555512002.0]\n",
    "pipa_date = '2015-01-01'\n",
    "pipa_results = analyze_mpa(geopoints_sampled, full_points, pipa, pipa_date)\n",
    "pipa_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 1/500 sampling\n",
    "pipa = mpas[mpas['WDPAID'] == 555512002.0]\n",
    "pipa_date = '2015-01-01'\n",
    "pipa_results = analyze_mpa(geopoints_sampled, full_points, pipa, pipa_date, plot_pre_post=False)\n",
    "pipa_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 1/1000 sampling\n",
    "pipa = mpas[mpas['WDPAID'] == 555512002.0]\n",
    "pipa_date = '2015-01-01'\n",
    "pipa_results = analyze_mpa(geopoints_sampled, full_points, pipa, pipa_date)\n",
    "pipa_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
